{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:19.053713Z","iopub.execute_input":"2022-04-26T22:37:19.054055Z","iopub.status.idle":"2022-04-26T22:37:19.787501Z","shell.execute_reply.started":"2022-04-26T22:37:19.053941Z","shell.execute_reply":"2022-04-26T22:37:19.786681Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\nimport IPython","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:19.789385Z","iopub.execute_input":"2022-04-26T22:37:19.789718Z","iopub.status.idle":"2022-04-26T22:37:24.969800Z","shell.execute_reply.started":"2022-04-26T22:37:19.789689Z","shell.execute_reply":"2022-04-26T22:37:24.969049Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/flickr-image-dataset/flickr30k_images'\nimage_dir = f'{data_dir}/flickr30k_images'\ncsv_file = f'{data_dir}/results.csv'\n\ndf = pd.read_csv(csv_file, delimiter='|')\n\nprint(f'[INFO] The shape of dataframe: {df.shape}')\nprint(f'[INFO] The columns in the dataframe: {df.columns}')\nprint(f'[INFO] Unique image names: {len(pd.unique(df[\"image_name\"]))}')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:24.970958Z","iopub.execute_input":"2022-04-26T22:37:24.973410Z","iopub.status.idle":"2022-04-26T22:37:25.358600Z","shell.execute_reply.started":"2022-04-26T22:37:24.973368Z","shell.execute_reply":"2022-04-26T22:37:25.357653Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"A quick observation here is to see that the dataframe has `158915` elements but only `31783` image names. This means that there is a duplicacy involved. On further inspection we will see that each image has 5 unique captions attached to it ($31783\\times 5=158915$)\n\nWhile looking into the dataframe I found out that `19999` had some messed up entries. This has led me to manually change the entries in that row.","metadata":{}},{"cell_type":"code","source":"df.columns = ['image_name', 'comment_number', 'comment']\ndel df['comment_number']\n\n# Under scrutiny I had found that 19999 had a messed up entry\ndf['comment'][19999] = ' A dog runs across the grass .'\n\n# Image names now correspond to the absolute position\ndf['image_name'] = image_dir+'/'+df['image_name']\n\n# <start> comment <end>\ndf['comment'] = \"<start> \"+df['comment']+\" <end>\"","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:25.360590Z","iopub.execute_input":"2022-04-26T22:37:25.361333Z","iopub.status.idle":"2022-04-26T22:37:25.462665Z","shell.execute_reply.started":"2022-04-26T22:37:25.361292Z","shell.execute_reply":"2022-04-26T22:37:25.461917Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Shuffle the dataframe\ndf = df.sample(frac=1).reset_index(drop=True)\nSIZE = len(df)\n\ntrain_size = int(0.7* SIZE) \nval_size = int(0.1* SIZE)\ntest_size = int(0.2* SIZE)\n\ntrain_size, val_size, test_size\n\ntrain_df = df.iloc[:train_size,:]\nval_df = df.iloc[train_size+1:train_size+val_size,:]\ntest_df = df.iloc[train_size+val_size+1:,:]","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:25.463843Z","iopub.execute_input":"2022-04-26T22:37:25.464602Z","iopub.status.idle":"2022-04-26T22:37:25.525899Z","shell.execute_reply.started":"2022-04-26T22:37:25.464558Z","shell.execute_reply":"2022-04-26T22:37:25.525159Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Splitting the dataframe accordingly","metadata":{}},{"cell_type":"code","source":"# Enter different indices.\nindex = 200\n\nimage_name = train_df['image_name'][index]\ncomment = train_df['comment'][index]\n\nprint(comment)\n\nIPython.display.Image(filename=image_name)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:25.527064Z","iopub.execute_input":"2022-04-26T22:37:25.527411Z","iopub.status.idle":"2022-04-26T22:37:25.553386Z","shell.execute_reply.started":"2022-04-26T22:37:25.527358Z","shell.execute_reply":"2022-04-26T22:37:25.552275Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Choose the top 5000 words from the vocabulary\ntop_k = 10000\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n                                                  oov_token=\"<unk>\",\n                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~')\n\n# build the vocabulary\ntokenizer.fit_on_texts(train_df['comment'])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:25.554304Z","iopub.execute_input":"2022-04-26T22:37:25.554556Z","iopub.status.idle":"2022-04-26T22:37:27.425750Z","shell.execute_reply.started":"2022-04-26T22:37:25.554520Z","shell.execute_reply":"2022-04-26T22:37:27.425030Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# This is a sanity check function\ndef check_vocab(word):\n    i = tokenizer.word_index[word]\n    print(f\"The index of the word: {i}\")\n    print(f\"Index {i} is word {tokenizer.index_word[i]}\")\n    \ncheck_vocab(\"pajama\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:27.426841Z","iopub.execute_input":"2022-04-26T22:37:27.427105Z","iopub.status.idle":"2022-04-26T22:37:27.434459Z","shell.execute_reply.started":"2022-04-26T22:37:27.427071Z","shell.execute_reply":"2022-04-26T22:37:27.433781Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Here we are padding the sentences so that each of the sentences are of the same length.","metadata":{}},{"cell_type":"code","source":"tokenizer.word_index['<pad>'] = 0\ntokenizer.index_word[0] = '<pad>'\n\n# Create the tokenized vectors\ntrain_seqs = tokenizer.texts_to_sequences(train_df['comment'])\nval_seqs = tokenizer.texts_to_sequences(val_df['comment'])\ntest_seqs = tokenizer.texts_to_sequences(test_df['comment'])\n\n# Pad each vector to the max_length of the captions\n# If you do not provide a max_length value, pad_sequences calculates it automatically\ntrain_cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\nval_cap_vector = tf.keras.preprocessing.sequence.pad_sequences(val_seqs, padding='post')\ntest_cap_vector = tf.keras.preprocessing.sequence.pad_sequences(test_seqs, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:27.435971Z","iopub.execute_input":"2022-04-26T22:37:27.436504Z","iopub.status.idle":"2022-04-26T22:37:30.759993Z","shell.execute_reply.started":"2022-04-26T22:37:27.436469Z","shell.execute_reply":"2022-04-26T22:37:30.759245Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_cap_ds = tf.data.Dataset.from_tensor_slices(train_cap_vector)\nval_cap_ds = tf.data.Dataset.from_tensor_slices(val_cap_vector)\ntest_cap_ds = tf.data.Dataset.from_tensor_slices(test_cap_vector)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:30.763080Z","iopub.execute_input":"2022-04-26T22:37:30.763340Z","iopub.status.idle":"2022-04-26T22:37:33.155182Z","shell.execute_reply.started":"2022-04-26T22:37:30.763305Z","shell.execute_reply":"2022-04-26T22:37:33.154421Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef load_img(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, (224, 224))\n    return img\n\ntrain_img_name = train_df['image_name'].values\nval_img_name = val_df['image_name'].values\ntest_img_name = test_df['image_name'].values\n\ntrain_img_ds = tf.data.Dataset.from_tensor_slices(train_img_name).map(load_img)\nval_img_ds = tf.data.Dataset.from_tensor_slices(val_img_name).map(load_img)\ntest_img_ds = tf.data.Dataset.from_tensor_slices(test_img_name).map(load_img)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:33.156273Z","iopub.execute_input":"2022-04-26T22:37:33.156909Z","iopub.status.idle":"2022-04-26T22:37:33.305374Z","shell.execute_reply.started":"2022-04-26T22:37:33.156863Z","shell.execute_reply":"2022-04-26T22:37:33.304638Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Joint data","metadata":{}},{"cell_type":"code","source":"# prefecth and batch the dataset\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 512\n\ntrain_ds = tf.data.Dataset.zip((train_img_ds, train_cap_ds)).shuffle(42).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\nval_ds = tf.data.Dataset.zip((val_img_ds, val_cap_ds)).shuffle(42).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\ntest_ds = tf.data.Dataset.zip((test_img_ds, test_cap_ds)).shuffle(42).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:37:33.306952Z","iopub.execute_input":"2022-04-26T22:37:33.307364Z","iopub.status.idle":"2022-04-26T22:37:33.329642Z","shell.execute_reply.started":"2022-04-26T22:37:33.307328Z","shell.execute_reply":"2022-04-26T22:37:33.328954Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Sanity check for the division of datasets","metadata":{}},{"cell_type":"code","source":"# Some global variables\nEMBEDDIN_DIM = 512\nVOCAB_SIZE = 10000\nUNITS_RNN = 256","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:09:55.760652Z","iopub.execute_input":"2022-04-26T23:09:55.761328Z","iopub.status.idle":"2022-04-26T23:09:55.765277Z","shell.execute_reply.started":"2022-04-26T23:09:55.761292Z","shell.execute_reply":"2022-04-26T23:09:55.764253Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class CNN_Encoder(tf.keras.Model):\n    \n    def __init__(self, embedding_dim):\n        super(CNN_Encoder, self).__init__()\n        self.embedding_dim = embedding_dim\n        \n    def build(self, input_shape):\n        self.resnet = tf.keras.applications.ResNet50(include_top=False,\n                                                     weights='imagenet')\n        self.resnet.trainable=False\n        self.gap = GlobalAveragePooling2D()\n        self.fc = Dense(units=self.embedding_dim,\n                        activation='sigmoid')\n        \n    def call(self, x):\n        x = self.resnet(x)\n        x = self.gap(x)\n        x = self.fc(x)\n        return x\n\n    # Checking the CNN\nencoder = CNN_Encoder(EMBEDDIN_DIM)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:09:56.138684Z","iopub.execute_input":"2022-04-26T23:09:56.139079Z","iopub.status.idle":"2022-04-26T23:09:56.176842Z","shell.execute_reply.started":"2022-04-26T23:09:56.139042Z","shell.execute_reply":"2022-04-26T23:09:56.176110Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class RNN_Decoder(tf.keras.Model):\n    def __init__(self, embedding_dim, units, vocab_size):\n        super(RNN_Decoder, self).__init__()\n        self.units = units\n        self.embedding_dim = embedding_dim\n        self.vocab_size = vocab_size\n        self.embedding = Embedding(input_dim=self.vocab_size,\n                                   output_dim=self.embedding_dim)\n    \n    def build(self, input_shape):\n        self.gru1 = GRU(units=self.units,\n                       return_sequences=True,\n                       return_state=True)\n        self.gru2 = GRU(units=self.units,\n                       return_sequences=True,\n                       return_state=True)\n        self.gru3 = GRU(units=self.units,\n                       return_sequences=True,\n                       return_state=True)\n        self.gru4 = GRU(units=self.units,\n                       return_sequences=True,\n                       return_state=True)\n        self.fc1 = Dense(self.units)\n        self.fc2 = Dense(self.vocab_size)\n\n    def call(self, x, initial_zero=False):\n        # x, (batch, 512)\n        # hidden, (batch, 256)\n        if initial_zero:\n            initial_state = decoder.reset_state(batch_size=x.shape[0])\n            output, state = self.gru1(inputs=x,\n                                      initial_state=initial_state)\n            output, state = self.gru2(inputs=output,\n                                      initial_state=initial_state)\n            output, state = self.gru3(inputs=output,\n                                      initial_state=initial_state)\n            output, state = self.gru4(inputs=output,\n                                      initial_state=initial_state)\n        else:\n            output, state = self.gru1(inputs=x)\n            output, state = self.gru2(inputs=output)\n            output, state = self.gru3(inputs=output)\n            output, state = self.gru4(inputs=output)\n        # output, (batch, 256)\n        x = self.fc1(output)\n        x = self.fc2(x)\n        \n        return x, state\n    \n    def embed(self, x):\n        return self.embedding(x)\n    \n    def reset_state(self, batch_size):\n        return tf.zeros((batch_size, self.units))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:09:56.367686Z","iopub.execute_input":"2022-04-26T23:09:56.367935Z","iopub.status.idle":"2022-04-26T23:09:56.380307Z","shell.execute_reply.started":"2022-04-26T23:09:56.367908Z","shell.execute_reply":"2022-04-26T23:09:56.379309Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Checking the RNN\ndecoder = RNN_Decoder(embedding_dim=EMBEDDIN_DIM,\n                      units=UNITS_RNN,\n                      vocab_size=VOCAB_SIZE)\nfor image, caption in train_ds.take(1):\n    features = tf.expand_dims(encoder(image),1) # (batch, 1, 128)\n    em_words = decoder.embed(caption)\n    x = tf.concat([features,em_words],axis=1)\n    print(x.shape)\n    predictions, state = decoder(x, True)\n    print(predictions.shape)\n    print(state.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:09:56.572941Z","iopub.execute_input":"2022-04-26T23:09:56.573473Z","iopub.status.idle":"2022-04-26T23:10:10.259426Z","shell.execute_reply.started":"2022-04-26T23:09:56.573440Z","shell.execute_reply":"2022-04-26T23:10:10.258663Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"encoder = CNN_Encoder(EMBEDDIN_DIM)\ndecoder = RNN_Decoder(embedding_dim=EMBEDDIN_DIM,\n                      units=UNITS_RNN,\n                      vocab_size=VOCAB_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:10:10.261148Z","iopub.execute_input":"2022-04-26T23:10:10.261909Z","iopub.status.idle":"2022-04-26T23:10:10.273363Z","shell.execute_reply.started":"2022-04-26T23:10:10.261865Z","shell.execute_reply":"2022-04-26T23:10:10.272657Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"We use `Adam` as the optimizer.\n\nThe loss is `SparseCategoricalCrossentropy`, because here it would be inefficient to use one-hot-encoders are the ground truth. We will also use mask to help mask the `<pad>` so that we do not let the sequence model learn to overfit on the same.","metadata":{}},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam()\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n\ndef loss_function(real, pred):\n    mask = tf.math.logical_not(tf.math.equal(real, 0))\n    loss_ = loss_object(real, pred)\n\n    mask = tf.cast(mask, dtype=loss_.dtype)\n    loss_ *= mask\n\n    return tf.reduce_mean(loss_)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:10:10.274498Z","iopub.execute_input":"2022-04-26T23:10:10.275498Z","iopub.status.idle":"2022-04-26T23:10:10.282239Z","shell.execute_reply.started":"2022-04-26T23:10:10.275461Z","shell.execute_reply":"2022-04-26T23:10:10.281448Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(img_tensor, target):\n    # img_tensor (batch, 224,224,3)\n    # target     (batch, 80)\n    loss = 0\n    with tf.GradientTape() as tape:\n        features = tf.expand_dims(encoder(img_tensor),1) # (batch, 1, 128)\n        em_words = decoder.embed(target)\n        x = tf.concat([features,em_words],axis=1)\n        predictions, _ = decoder(x, True)\n\n        loss = loss_function(target[:,1:], predictions[:,1:-1,:])\n\n    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n\n    gradients = tape.gradient(loss, trainable_variables)\n\n    optimizer.apply_gradients(zip(gradients, trainable_variables))\n\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:10:10.284069Z","iopub.execute_input":"2022-04-26T23:10:10.284319Z","iopub.status.idle":"2022-04-26T23:10:10.292332Z","shell.execute_reply.started":"2022-04-26T23:10:10.284284Z","shell.execute_reply":"2022-04-26T23:10:10.291406Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef val_step(img_tensor, target):\n    # img_tensor (batch, 224,224,3)\n    # target     (batch, 80)\n    loss = 0\n    features = tf.expand_dims(encoder(img_tensor),1) # (batch, 1, 128)\n    em_words = decoder.embed(target)\n    x = tf.concat([features,em_words],axis=1)\n    predictions, _ = decoder(x, True)\n    loss = loss_function(target[:,1:], predictions[:,1:-1,:])\n    \n    loss = train_step(img_tensor, target)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:10:41.802724Z","iopub.execute_input":"2022-04-26T23:10:41.802976Z","iopub.status.idle":"2022-04-26T23:10:41.810743Z","shell.execute_reply.started":"2022-04-26T23:10:41.802947Z","shell.execute_reply":"2022-04-26T23:10:41.809909Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\nEPOCHS = 10\nepoch_wise_loss = []\nepoch_wise_val_loss = []\nfor epoch in range(EPOCHS):\n    batch_wise_loss = []\n    for (batch, (img_tensor, target)) in enumerate(train_ds):\n        loss = train_step(img_tensor, target)\n        batch_wise_loss.append(loss.numpy())\n        if batch%100 == 0:\n            print(f'Epoch: {epoch} Batch: {batch} Loss: {batch_wise_loss[-1]:.3f}')\n   \n    epoch_wise_loss.append(np.mean(batch_wise_loss))\n\n    batch_wise_val_loss = []\n    for (batch, (img_tensor, target)) in enumerate(val_ds):\n        loss = val_step(img_tensor, target)\n        batch_wise_val_loss.append(loss.numpy())\n    epoch_wise_val_loss.append(np.mean(batch_wise_val_loss))\n    print(f'Epoch: {epoch} Total Loss: {epoch_wise_loss[-1]:.3f} Val Loss:{epoch_wise_val_loss[-1]:.3f}')\n    print('-'*40)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T23:10:45.103125Z","iopub.execute_input":"2022-04-26T23:10:45.103660Z","iopub.status.idle":"2022-04-27T00:26:16.186467Z","shell.execute_reply.started":"2022-04-26T23:10:45.103621Z","shell.execute_reply":"2022-04-27T00:26:16.185667Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Save the weights","metadata":{}},{"cell_type":"code","source":"!mkdir models\nencoder.save_weights('./models/encoder.h5')\ndecoder.save_weights('./models/decoder.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T00:31:23.205976Z","iopub.execute_input":"2022-04-27T00:31:23.206264Z","iopub.status.idle":"2022-04-27T00:31:24.379805Z","shell.execute_reply.started":"2022-04-27T00:31:23.206235Z","shell.execute_reply":"2022-04-27T00:31:24.378934Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n## Total Loss","metadata":{}},{"cell_type":"code","source":"encoder = CNN_Encoder(EMBEDDIN_DIM)\nfor image, caption in train_ds.take(1):\n    encoder(image)\n\ndecoder = RNN_Decoder(embedding_dim=EMBEDDIN_DIM,\n                      units=UNITS_RNN,\n                      vocab_size=VOCAB_SIZE)\nfor image, caption in train_ds.take(1):\n    features = tf.expand_dims(encoder(image),1)\n    em_words = decoder.embed(caption)\n    x = tf.concat([features,em_words],axis=1)\n    predictions, state = decoder(x, True)\n\nencoder.load_weights('./models/encoder.h5')\ndecoder.load_weights('./models/decoder.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T00:31:26.307937Z","iopub.execute_input":"2022-04-27T00:31:26.308452Z","iopub.status.idle":"2022-04-27T00:31:35.034329Z","shell.execute_reply.started":"2022-04-27T00:31:26.308413Z","shell.execute_reply":"2022-04-27T00:31:35.033563Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"data = []\nfor img, cap in test_ds.take(1):\n   \n    img = tf.expand_dims(img[0],0)\n    cap = tf.expand_dims(cap[0],0)\n\n    feature = tf.expand_dims(encoder(img),1) # (1, 1, 128)\n    prediction, _ = decoder(feature, True)\n\n    word = tf.reshape(tokenizer.word_index['<start>'], shape=(1,1))\n    em_words = decoder.embed(word)\n\n    prediction, _ = decoder(em_words)\n    idx = tf.random.categorical(tf.squeeze(prediction,1), 1)[0][0].numpy()\n    word = tokenizer.index_word[idx]\n\n    count = 0\n    catption = ''\n    while word != '<end>':\n        print(word, end=\" \")\n        caption += word\n        word_int = tf.reshape(tokenizer.word_index[word], shape=(1,1))  \n        em_words = decoder.embed(word_int)\n        prediction, _ = decoder(em_words)\n        idx = tf.random.categorical(tf.squeeze(prediction,1), 1)[0][0].numpy()\n        word = tokenizer.index_word[idx]\n    \n    data.append(img, caption)\n        \ndf_test = pd.DataFrame(data)\nprint(\"test DF Created with captions\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T00:32:17.797756Z","iopub.execute_input":"2022-04-27T00:32:17.798053Z","iopub.status.idle":"2022-04-27T00:32:17.802316Z","shell.execute_reply.started":"2022-04-27T00:32:17.798017Z","shell.execute_reply":"2022-04-27T00:32:17.801502Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df_test.to_csv('df_test_caption.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T22:28:25.286421Z","iopub.execute_input":"2022-04-26T22:28:25.286941Z","iopub.status.idle":"2022-04-26T22:28:25.293158Z","shell.execute_reply.started":"2022-04-26T22:28:25.286898Z","shell.execute_reply":"2022-04-26T22:28:25.292266Z"},"trusted":true},"execution_count":null,"outputs":[]}]}